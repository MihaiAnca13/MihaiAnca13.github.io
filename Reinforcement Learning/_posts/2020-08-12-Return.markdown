---
layout: post
title:  "Return"
date:   2020-08-12 09:25:00 +0100
---
# Back to work
Before the break, the last change was the introduction of normalization. The problem was that the training after this new feature was added behaved differently. Normalization was supposed to help the neural network find features.

## Ideas to try
In order to debug, all experiences created could be printed. Once the normalization code is fixed, a new experiment can be done:
- stop *transitions* when goal is reached but then check if it's only a 1 length transition. This would remove the transitions when the object is not touched. This could be beneficial because currently there are transitions being created where the object is not touched and the goal is moved on top of it.

### Fixing normalization
Last time, all variables calculated by the Normalizer class were displayed at the end of the training. The values displayed were different from the ground truth. Unfortunately, those values could not be used to initialize the normalizer because the high level generated too many similar points. This resulted in a very biased mean and std. Because those values are not stable in the beginning of the training, maybe the network realizes that by restricting the movement, it can cover more of the workspace over time. 

Initializing the normalizer through a couple hundreds of episodes could help, however, the positions covered by random movements are quite limited. It feels like the best approach would be to calculate all values using the ground truth and setting the `sample count` to a high value. However, this approach presents two issues:
1. the standard deviation would be equal to 0 if using ground truth values rather than actual sums
2. the only values known for the ground truth are those related to the workspace. Unfortunately, there are 25 axis, some of which include velocities, which cannot be easily predicted without experimentation.

The approach of choice would be to run the initializer for a couple hundreds of episodes. Then, some examples would be run with the `denormalize` function to check what the discrepancy is after a couple of episodes of training.

Values after 1000 episodes:
~~~ python
Mean: tensor([ 1.3311e+00,  7.4950e-01,  5.2273e-01,  1.3556e+00,  7.4984e-01,
         4.2374e-01,  2.4501e-02,  3.1696e-04, -9.8820e-02,  2.8026e-02,
         2.7989e-02, -1.4775e-02,  2.9946e-02,  6.2490e-03,  5.3685e-04,
        -1.4069e-05, -1.4119e-03, -3.5463e-04,  1.1977e-03, -8.0967e-08,
        -2.1983e-04, -8.9861e-06,  4.3324e-04,  2.0297e-04,  1.9778e-04,
        -1.4208e-04, -7.3963e-04, -2.1467e-03, -9.1255e-05]) 
 Std: tensor([0.0859, 0.0947, 0.0744, 0.0935, 0.0891, 0.0443, 0.1207, 0.1208, 0.0840,
        0.0166, 0.0166, 0.5965, 0.2830, 0.5913, 0.0147, 0.0149, 0.0158, 0.0614,
        0.0461, 0.0523, 0.0146, 0.0150, 0.0148, 0.0090, 0.0090, 0.5789, 0.5767,
        0.5773, 0.0289]) 
 Sum: tensor([ 6.6557e+04,  3.7475e+04,  2.6136e+04,  6.7781e+04,  3.7492e+04,
         2.1187e+04,  1.2251e+03,  1.5848e+01, -4.9410e+03,  1.4013e+03,
         1.3994e+03, -7.3873e+02,  1.4973e+03,  3.1245e+02,  2.6842e+01,
        -7.0346e-01, -7.0593e+01, -1.7732e+01,  5.9886e+01, -4.0483e-03,
        -1.0992e+01, -4.4931e-01,  2.1662e+01,  1.0149e+01,  9.8891e+00,
        -7.1042e+00, -3.6982e+01, -1.0733e+02, -4.5628e+00]) 
 Sum_Squares: tensor([8.8965e+04, 2.8536e+04, 1.3939e+04, 9.2321e+04, 2.8510e+04, 9.0760e+03,
        7.5842e+02, 7.2919e+02, 8.4079e+02, 5.3005e+01, 5.2911e+01, 1.7802e+04,
        4.0502e+03, 1.7481e+04, 1.0781e+01, 1.1159e+01, 1.2568e+01, 1.8852e+02,
        1.0641e+02, 1.3699e+02, 1.0709e+01, 1.1283e+01, 1.0944e+01, 4.0139e+00,
        4.0331e+00, 1.6754e+04, 1.6631e+04, 1.6661e+04, 4.1817e+01]) 
 Count: tensor([50000], dtype=torch.int32)
 ~~~

 The goals generated by the high level are now more varied. Training will continue for a bit longer to determine if this fixed the problem completely. After 1.5k p.p.p., the high level seems to generate very similar target at each test. However, the movements are smooth and this seems to be a different problem. Hopefully, this can be solved by tweaking the learning rates. Here are the new values:
~~~ python
Mean: tensor([ 1.2488e+00,  6.7215e-01,  5.8648e-01,  1.3417e+00,  7.0511e-01,
         4.2495e-01,  9.2777e-02,  3.3163e-02, -1.6046e-01,  3.2886e-02,
         3.2846e-02,  1.6553e-02,  1.9306e-02,  9.1152e-02,  1.9468e-03,
         8.0815e-04, -2.2648e-03,  6.3388e-04,  4.5752e-04,  1.1646e-03,
        -1.9506e-03, -1.6385e-03,  1.1715e-03,  2.5889e-04,  2.9070e-04,
        -2.9732e-02, -9.6862e-02,  7.1217e-02,  1.1615e-02]) 
 Std: tensor([0.1372, 0.2426, 0.1256, 0.1028, 0.1378, 0.0674, 0.1672, 0.2324, 0.1364,
        0.0204, 0.0204, 0.5126, 0.2345, 0.6848, 0.0150, 0.0167, 0.0183, 0.0475,
        0.0375, 0.0501, 0.0153, 0.0171, 0.0167, 0.0078, 0.0078, 0.7241, 0.7104,
        0.6804, 0.0439]) 
 Sum: tensor([ 8.2296e+05,  4.4296e+05,  3.8650e+05,  8.8418e+05,  4.6468e+05,
         2.8005e+05,  6.1142e+04,  2.1855e+04, -1.0574e+05,  2.1672e+04,
         2.1646e+04,  1.0909e+04,  1.2723e+04,  6.0071e+04,  1.2829e+03,
         5.3259e+02, -1.4926e+03,  4.1774e+02,  3.0151e+02,  7.6747e+02,
        -1.2855e+03, -1.0798e+03,  7.7201e+02,  1.7062e+02,  1.9158e+02,
        -1.9594e+04, -6.3834e+04,  4.6933e+04,  7.6542e+03]) 
 Sum_Squares: tensor([1.0401e+06, 3.3651e+05, 2.3707e+05, 1.1932e+06, 3.4016e+05, 1.2200e+05,
        2.4093e+04, 3.6333e+04, 2.9235e+04, 9.8651e+02, 9.8531e+02, 1.7337e+05,
        3.6480e+04, 3.1456e+05, 1.5156e+02, 1.8342e+02, 2.2483e+02, 1.4870e+03,
        9.2717e+02, 1.6567e+03, 1.5712e+02, 1.9355e+02, 1.8517e+02, 4.0016e+01,
        3.9907e+01, 3.4610e+05, 3.3880e+05, 3.0846e+05, 1.3588e+03]) 
 Count: tensor([659018], dtype=torch.int32)
~~~

Computing the difference:
~~~ python
Mean:  [ 0.082  0.077 -0.064  0.014  0.045 -0.001 -0.068 -0.033  0.062 -0.005
 -0.005 -0.031  0.011 -0.085 -0.001 -0.001  0.001 -0.001  0.001 -0.001
  0.002  0.002 -0.001 -0.    -0.     0.03   0.096 -0.073 -0.012]
Std:  [-0.051 -0.148 -0.051 -0.009 -0.049 -0.023 -0.046 -0.112 -0.052 -0.004
 -0.004  0.084  0.048 -0.093 -0.    -0.002 -0.002  0.014  0.009  0.002
 -0.001 -0.002 -0.002  0.001  0.001 -0.145 -0.134 -0.103 -0.015]
~~~

By calculating the deviation for each axis, the ones with considerable changes are: 
- 7 - part of object relative position
- 13 - part of gripper velocity
- 15 - part of gripper velocity
- 19 - part of goal position
- 21 - part of goal relative position
- 25 - part of action
- 26 - part of action
- 27 - part of action
- 28 - part of action


<!-- ![Bug found](/assets/Common/bug-stop.png){: .center-image} -->

<!-- ![Low level accuracy](/assets/Normalization-3/0_accuracy.png)
![Low level actor loss](/assets/Normalization-3/0_loss_actor.png)
![Low level critic loss](/assets/Normalization-3/0_loss_critic.png)
![Low level reward](/assets/Normalization-3/0_reward.png)
![High level accuracy](/assets/Normalization-3/1_accuracy.png)
![High level actor loss](/assets/Normalization-3/1_loss_actor.png)
![High level critic loss](/assets/Normalization-3/1_loss_critic.png)
![High level accuracy](/assets/Normalization-3/1_reward.png) -->